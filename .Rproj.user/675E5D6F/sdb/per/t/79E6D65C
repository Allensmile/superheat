{
    "collab_server" : "",
    "contents" : "\\documentclass[12pt]{article}\n\n\n\\usepackage{amsmath}\n\\usepackage{graphicx,psfrag,epsf}\n\\usepackage{enumerate}\n\\usepackage{url} % not crucial - just used below for the URL\n\\usepackage{float}\n\\usepackage{array}\n\\usepackage{amsmath}\n\\usepackage{hyperref}\n\\usepackage{longtable}\n\\usepackage{xcolor}\n\\usepackage{amsfonts}\n\n\\RequirePackage{natbib}\n\n\n\n\\title{Anomaly Detection for Precision Medicine}\n\\author{Rebecca Barter}\n\n\\begin{document}\n\n\\bibliographystyle{chicago}\n\n\\maketitle\n\nThis document reviews a wide spread of literature concerning outlier detection and it's place in the realm of high dimensional distance metrics, and algorithmic procedures such as random forest.\n\nWhen one discusses an ``outlier'', it is common to specify a distance metric which describes the sense in which the data point is \\textit{far away} from the majority. However, as we begin to move towards realms of high dimensions, this notion of far away becomes increasingly complex and uninterpretable.\n\nThere is a substantial recent literature discussing why common distance metrics, such as the Euclidean distance, are undesirable in the realm of high dimensions \\cite{aggarwal_surprising_2001},\n\n\n\\section{Techniques for anomaly detection}\n\n\n\\subsection{\\cite{liu_isolation-based_2012}: The Isolation Forest}\n\nMost existing methods for anomaly detection first construct a profile of ``normal'' instances, and then identify those that don't conform to the newly defined normal profile (for references see the first paragraph of \\cite{liu_isolation-based_2012}). These algorithms usually focus on a by-product of an algorithm that is usually designed for a purpose other than anomaly detection (such as classification or clustering).\n\n\\cite{liu_isolation-based_2012} developed a method for detecting anomalies without relying on any distance or density measure. Their approach relies on the assumption that anomalies are rare and very different from the normal instances. They can be identified using ``isolation'' captured by the \\textit{Isolation Forest}, or \\textit{i}Forest. The method relies on an assumption that all variables in a dataset contribute equally to anomaly detection (\\textit{this could probably be weakened by using some kind of feature importance measure...?})\n\nThe notion of ``isolation'' can be realized using binary trees where instances are recursively partitioned, wherein if it only takes a small number of partitions taken to isolate a data point in its own leaf, it can be seen to have a high isolation propensity. For example, we need significantly fewer partitions to isolate $x_0$ than we need to isolate $x_i$ (a more typical data point) in the figures below.\n\n\\begin{figure}[H]\n\\centering\n\\includegraphics[scale = 0.5]{isolation.png}\n\\end{figure}\n\nIn this example, partitions are generated by randomly selecting an attribute, and then randomly selecting a split value between the min and max values of the attribute. The average path length leading to an isolated partition provides a very nice indication of isolation propensity.\n\n\n\n\\subsection{\\cite{guha_robust_2016}}\n\n\n\\cite{guha_robust_2016} view the problem of \\textit{detecting} anomalies in a similar way as the iForest of \\cite{liu_isolation-based_2012}. They are also interested in \\textit{defining} anomalies as data points whose inclusion in a model substantially increases its complexity. The authors argue that the presence of irrelevant dimensions in the implementation of iForest can cause crucial anomalies to be missed. They thus propose an extension to the iForest, the \\textit{robust random cut tree (RRCT)}, which randomly selects the variable to cut with probability proportional to it's range (the iForest selected the variables uniformly at random).\n\n\n\\subsection{\\cite{friedman_bump_1998}}\n\n\n\n\n\\section{Random Forest}\n\n\n\n\\section{New notions of distance in high dimensions}\n\n\\section{The random structure of databases}\n\n\\section{Existing applications to personalized medicine}\n\n\n\\bibliography{Diagnostics}\n\n\\end{document}\n",
    "created" : 1475016430480.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1596769721",
    "id" : "79E6D65C",
    "lastKnownWriteTime" : 1475017581,
    "last_content_update" : 1475017581114,
    "path" : "~/Google Drive/Berkeley PhD/Research/Anomaly Detection/Review.Rnw",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "sweave"
}